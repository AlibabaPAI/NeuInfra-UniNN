# Tri-Blade : A Triton-Powered Kernel Library for LLM Serving

Tri-Blade is a pioneering kernel library for Large Language Models (LLMs), providing a high-performance implementation of GPU kernels optimized for LLM serving and inference, involving in comprehensive support for attention kernels and versatile quantization methods. 

By harnessing the power of Triton, Tri-Blade is engineered to seamlessly integrate with multiple of hardware platforms, ensuring smooth operability and maximizing the utilization of hardware resources.



## Features

- **Comprehensive Support for Attention Kernels**: Tri-Blade offers extensive support for various types of attention mechanisms, enabling it to handle a wide array of LLM architectures with ease. 
- **Multiple Quantization Methods**: Tri-Blade incorporates multiple quantization techniques (int8, int4) aimed at optimizing both the computational overhead and the memory footprint of LLMs, making it easier to deploy LLMs in resource-constrained environments.
- **Production-Ready Performance**: Tri-Blade is meticulously optimized for production scenarios, which delivers state-of-art performance that meets the demanding requirements of real-world applications.
- **Smooth Portability on Multiple Hardware**: Facilitated by the inherent design of the Triton language, Tri-Blade simplifying the process of adapting LLM serving solutions to diverse computing environments.



## Get Started


### Requirements

### Installation

### Run tests



## Benchmark



## License



## Acknowledgements
